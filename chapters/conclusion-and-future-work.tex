\section{Conclusion}

In this thesis, we described and demonstrated \demo{}, a tool we propose
for visualizing performance in overlay-based pub/sub systems. We
presented a poster and held a live demonstration of \demo{} at the ACM
International Conference of Distributed Event Based Systems (DEBS), held
in Mumbai in May 2014, where it was awarded the price for best poster
and demo.

To the best of our knowledge, this is the first tool of its kind which
enable easy and efficient visual inspection and analysis of pub/sub
overlays. The thesis includes several example scenarios where \demo{}
proved to be a useful tool for us in both analyzing as well as debugging
pub/sub protocols. Although our main focus is visualizing pub/sub
systems, \demo{} is a generic tool, intended to support any overlay-
based system. For this purpose, we define a generic interface, which is
the only point of contact between any client code (i.e.\ overlay-based system)
an our framework. The implementation of this interface is the only
system specific part of our tool.

We demonstrated our tool further, by providing examples of
visualizations. To summarize, \demo{} supports two different types of
visualizations: (1) visualizations of overlay structure and (2)
visualizations of publication message dissemination. The former provides
a step-by-step visualization of disseminating events, by drawing
directed edges which depicts the paths of messages. Also, numeric text
labels are applied to nodes which represent the hop count of the
publication messages received. We also show how users may also derive
the message duplication count by calculating the in-degree of the
visualization. We show an example of this type of visualization where we
disseminate a single message on a single topic in
PolderCast~\cite{Setty:2012}. The example shows the utility of
visualizing publication messages disseminations, both for researchers
who wants to analyze the dissemination scheme of their protocol, of
developers who want to debug the algorithms used for disseminating
messages, as well as for students who wants a deep understanding of the
particular dissemination process.

We also provided several examples of visualizations which describe the
structure of the overlay, as well as providing examples on how to
visualize certain metrics of pub/sub systems through color and text
labels. We used these capabilities in order to
visually compare two different pub/sub systems, namely PolderCast and
Scribe~\cite{Castro:2002}. We also used the capability of the Gephi Open
Graph Viz tool~\cite{ICWSM09154} in order to produce plots describing
the distribution of degree as well as time series of metrics such as
number of edges, degree and clustering coefficient.

Finally, we tested the capabilities of \demo{} as a framework for
evaluating pub/sub systems on a set of particular topology metrics. The
implementation code for running these metrics are provided by the Gephi
framework ``for free'' through the API provided by the \emph{Gephi
    Toolkit}. The evaluation revealed the overlay in Scribe changes
drastically in terms of number of edges depending on the workload used
to model subscriptions. It also seems to indicate that Scribe is more
vulnerable to churn than PolderCast, as several nodes are disconnected.
However, further evaluation is needed at larger scale in order to
investigate these issues properly.

In addition to describing and demonstrating \demo{}, we also provide a
mini-survey, which compares several popular pub/sub protocols both on
on the structure of their overlays as well as their dissemination
properties. In this comparison we focus on the difficult design
decisions researchers face when developing such systems.

We hope our description of our proposed tool and the examples laid out
in this thesis makes a convincing case for its utility as a tool for
researchers, developers and students alike. The educational benefit of
\demo{} is particularly exciting. Being able to study and experiment
with graphs in such a visual and hands-on fashion should provide a very
engaging experience for students who are entering the field of
distributed systems. We also believe researchers can benefit from the
tool, as it provides a deeper insight about the overlay structure as
well as the dissemination process. For anyone developing an
overlay-based system, whether it implements the pub/sub paradigm or not,
\demo{} can act as a powerful tool for debugging. In this thesis, we
provided several example scenarios where we experienced the usefulness
of our tool first-hand.

As mentioned, we are not aware of any other proposed tool which is quite
comparable in terms of enabling visual analysis of pub/sub systems. And
although we imagine numerous possible use cases for \demo{}, the
possibilities of such a tool is still relatively unknown. We hope  the
research community or any party interested will look at our tool, test
it, modify it, extend it and in general find uses for it. During the
poster and demonstration of \demo{} we held at DEBS2014, we were
approached by several participant who expressed their interest in using
such a tool for their own research.  This is why we choose to host our
implementation code of \demo{} in a public
repository. We hope the
tool will serve as a lasting contribution to the research community, as
well as aid in recruiting more students to our field of research.

\section{Future Work}

We believe there is a lot of potential for a tool such as \demo{}. What
we present in this thesis is currently only a prototype, but hopefully
it can serve as a starting point for further improvements. In this
section we will discuss some of these potential improvements to \demo{},
as well as some of the issues and limitations we faced in our implementation work.

\subsection{Further Evaluation}

Due to time constraints, we were unable to perform a more extensive
evaluation with several configurations. In particular, we would have
liked to compare PolderCast and Scribe on a set of dissemination metrics
such as \emph{hit-ratio}, \emph{path lengths} as well as compare the messaging
overhead in terms of number of control messages. We expect the result
would show that that PolderCast has a higher hit-ratio and lower path
lengths at the expense of higher loads. However, we have been unable to
show this through an evaluation.

\subsection{Improving Report File Sizes}

Currently, the biggest issue with \demo{} is scalability in terms of
file sizes. Both the Reporter and Collector stores temporary files
which can be quite large depending on the scale of the system in terms
of number of nodes, edges as well as number of topics and publication
messages being posted on each topic. During our experiments we ran into
several issues due to restrictions in disk quota on the machine cluster.
In particular, a high number of edges cause issues, especially if any
attributes are applied to them. But also the number of publication
messages will bloat file sizes of the temporary logs considerably. This
causes performance issues when the Collector collates these files into
the final report. The final report also scales poorly in terms of file
size due to the \gexf{} format being based on XML, which stores data in
a declarative text based format. The file sizes of the final report can
grow up to several gigabytes, which causes big performance issues when
opening these files in Gephi. Due to these performance issues we had to
restrict the scale of our experiments. This is unfortunate, and the
issues with performance should be addressed quickly in order to increase
the scalability of the system. Fortunately, there is a lot of
potential in terms of increasing the performance of the system,
as it is still in the prototype stage.

\subsection{Implementing Database Support}

Instead of processing log files, it could be useful to take advantage a
database for persistence. Graph databases would be an obvious fit for a
tool such as \demo{}. There is already a Gephi plugin for importing and
exporting data to such a database, but it is immature and does not
support the latest version of the
database.\footnote{https://marketplace.gephi.org/plugin/neo4j-graph-database-support/}.
Regardless, implementing graph database support is most likely a more
scalable approach to handling the large amount of data retrieved from
the reporters.

\subsection{Gephi Performance Issues}

There are also performance issues with Gephi, as it is still in version
0.8.7. Currently, Gephi is very memory intensive, due to the data model
it uses for storing graphs. However, the authors have dealt with this
issue in the current development version, where the memory usage has
been significantly decreased. However, this version also breaks some
features which prevents us from using it. As the development version is
still pre-1.0 and rather unstable, we rather choose to wait for it to
reach a stable 1.0 version before making any major changes to our tools
compatibility. Also, pre-1.0 software usually involves a lot of changes
which breaks backwards compatibility. This means users of \demo{}
currently need to use version the 0.8.7 of Gephi until a stable 1.0
version is released.

Another important point to make regarding performance in Gephi is the
use of the OpenGL graphics library when rendering graphs. This means
that in order to open large graphs in Gephi, it is necessary to use a
computer with a dedicated graphics card. The bigger the Graph, the more
graphics capability is required.

\subsection{Reporter Performance Issues}

The reporter has some performance issues due to allocating new Java
objects each time the Collector pulls data. This causes the Java process to
hang, as the garbage collector kicks in to clean up the heap. This is an
issue which should be fixed by allocating memory statically and
overwriting memory rather re-allocating it. Also, this is a potential bottleneck
in the system with regards to memory usage. If the reports are very large, the Java
objects might occupy too much  memory, causing the Java process to
fail. However, this should only be an issue when  running simulations at
scale, where a process might include several simulated PeerNet nodes but only one
reporter.

\subsection{Visualizing with Custom Colors and Sizes}

Most of the visualizations in this thesis use text labels and color in
order to convey information regarding the performance of the pub/sub
system in question. However, it would also be interesting to visualize
metrics using shapes, sizes and custom colors. For example, edges could
be of different thickness, according to how many topic attributes were
added to them. Also, special nodes such as the \emph{rendezvous} nodes
in Scribe could have a custom color to them in order to identify them
easily. Alternatively, the ``special'' nodes could be of a different
sizes than ``regular'' nodes. This is different than the current way of
applying colors through the \emph{Statistics Component} in Gephi, as it
is dependent on the existence of a node attribute. Any custom color or
size would have to be applied by the Collector. However, due to a bug in
the external software
library\footnote{\url{http://https://github.com/francesco-ficarola/gexf4j}}
used to build the \gexf{} files, this was not possible to implement.


\subsection{Collector Scalability}

In the current implementation of \demo{}, the collector is run in a
single JVM instance, where the pub/sub nodes connect to it via TCP.\
There might be issues with the scalability in terms of number of
connections, as we have not been able to test the system with more than
30 connections. The Collector also serve as a single point of failure.
Ideally, the Collector should itself be a distributed system, with
built-in fault tolerance and a replication scheme. This is an important
if \demo{} is ever to be considered \emph{production ready}, i.e.\ ever
being used in real, deployed pub/sub systems. This is not a pressing
concern however, as \demo{} is still a far way from being production
ready, but hopefully it will be in the future.

\subsection{Including Associative Arrays in Gephi}

It would be useful to be able to store a map data structure on each
graph, i.e.\ associative arrays. If associative arrays were supported,
a user could derive information such as how many duplicate messages a
particular node received on a specific topic or single dissemination
session. Also, it would enable the user to see how many publication messages a
particular node sent or received for a specific topic. Implementing such
a structure will most likely involve modifying the source code of Gephi.
This is fully possible, since Gephi is an open source product and hosted
in a public repository.\footnote{\url{http://github.com/gephi/gephi}}
This would require quite an effort however, as the code base is quite
large and it would take time to gain the necessary insight into it.

\subsection{Implementing Global Attribute Visualization}

Currently, it is not possible to visualize graph attributes in Gephi, or
indeed list any global attribute in the graph. This would be a useful
feature to implement as a plugin. For example, it would be helpful to be
able to list all topics on the graph and sort then according to number
of subscribers. Our workaround for this is to apply a node label to all
nodes which describes a global attribute. Such global attributes include
hit-ratio and average control messages sent and received. Visualizing
these attributes on every node can be misleading, as it gives the
impression that the values are unique to every node. It would be better
to display these values in a separate panel, or perhaps even as a large
floating text label in the Graph view.

\subsection{\demo{} as an Interactive Monitoring System}

As mentioned, the visualization of pub/sub systems are done offline,
after the execution of the pub/sub system is finished. It is not
intended to be a real-time system, where data is pulled and metrics are
calculated during system execution. When inspecting the overlay using
the \emph{Visualization Unit}, users may delete nodes in order to
determine the effect it has on the overlay topology by recalculation
such metrics using the \emph{Statistics Component} in Gephi. However, it will
not affect any custom metrics which are calculated by the Collector such
as control messages sent and received as these metrics are calculated
after the execution of the pub/sub system. In order to affect such
metrics, the architecture would have to be changed in order to
accommodate for a two-way communication, where the Collector would be
able to issue commands to the pub/sub nodes. Also, the Collector would
have to collect data, calculate metrics and stream this information to
Gephi in real-time. Gephi does indeed include an API for streaming data,
so it is possible in theory, although in practice there are some issues
with this API.\ This would be incredibly useful however, both as a
monitoring system and as an environment for experimenting with protocols
and their behavior. For example, imagine being able to right-click a
node in Gephi, and ask this node leave the network. The Collector would
then issue a leave command to the node in question, and the user could
then potentially observe what happens in the Visualization Unit. The
interactivity of such a feature would be incredibly engaging and useful
both for developers and researchers, as well as students. Such
a feature requires extensive re-engineering of \demo{}, but would be
well worth the effort.

\subsection{Playback issues in the Timeline component}

We encountered some issues related to the playback of dynamic
graphs in Gephi. The playback is based on time intervals, where the
start and end bounds for the interval is encoded as a double. As you
play back the graph evolution, these bounds suffer from rounding errors,
which might lead to an interval that overlaps to simulation states.
These intervals are effectively filter, stripping the graph of nodes and
edges that do not belong in the defined interval. However, if the
interval crosses the boundary of two different simulation states, the
edges and nodes from both states will be included, which often leads to
a sudden increase in number of edges during the animation, which
abruptly disappear again. However, this issue is easily worked around by
defining a sufficiently short interval. We usually set the interval
bound to be of length 0.1, as this in our experience never leads to the
issues with the time interval overlapping different states. We confirmed
this by playing back the graph and controlling the start and end bounds
output on the Filter component, as well as visually confirming the
absence of any edge animation irregularities. Testing with the Cyclon
protocol, we were also able to visually confirm that the number of edges
remain consistent for each cycle in the context pane on the top right
side of the Gephi GUI\@.
