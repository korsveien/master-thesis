In this chapter, we test the capabilities of  \demo{} as a framewor for
evalutating pub/sub systems. We extend the evaluation of PolderCast and
Scribe found in~\cite{Setty:2012} on a set of topology metrics. These
metrics are afforded to us for ``free'' by the Gephi framework through
the Statistics API included in the \emph{Gephi Toolkit}.

\section{\demo as a Framework for Evaluating Pub/Sub Systems}
\label{sec:viz_eval}

Although the plots seen in Chapter~\ref{ch:vizpub} are easy to produce
in Gephi, they are not very flexible. For example, it would be useful to
be able to superimpose two plots on top of each other in order to
effectively compare them. Therefore, in addition to outputting a \gexf
file which can be used to produce visualizations and plots in Gephi, The
collector is also able to generate \csv files which can be used to plot
a time series of metrics such as degree, clustering coefficient and
centralities. Each time point in the time series will represent a
\emph{Reporter Interval}. Although the Data Laboratory component in
Gephi is able to output such \csv files, it is much more convenient to
output them directly from the Collector, as opening the Gephi GUI-client
for the sole purpose of producing such files manually is more time
consuming, especially on older hardware, or machines without a dedicated
graphics card. The Collector is able to do this trough the Gephi
Toolkit, which provides an API for the major components of Gephi. Which
overlay properties to output is configurable in the Collector.
Currently, the supported metrics that can be exported to \csv files by
the Collector include:

\begin{itemize}
    \item Undirected Degree
    \item In-Degree
    \item Out-Degree
    \item Clustering Coefficient
    \item Betweenness Centrality
    \item Closeness Centrality
    \item Eccentricity Centrality
    \item Topic Diameter
    \item Size of Network
\end{itemize}

This grants researchers and developers of pub/sub protocols who wish to evaluate
the system in question immediate access to several metrics. They do not need to
reimplement algorithms for the metric calculations themselves. All that is
required is to implement the \emph{reporter interface}.

The plots produced aim at resembling the plots produced by the
Statistics Component in Gephi. However, due to using an external tool
for plotting, we can superimpose several plots on top of each other, as
well as adjust the format and layout of the plots. Also, it should be
noted that the output file format of the Gephi plots are non-vector
image files, which is not suitable for printing. The ability choose the
image format of the plots is another benefit over using the
standard plot output of Gephi.

\section{Experimental Restrictions}

As our implementation of \demo{} still is an early prototype.

\section{Experimental Setup}

We run PolderCast and Scribe in PeerNet using the simulation mode. The
Simulations consists of 1000 PeerNet cycles as well as 1000 reporter
intervals. We use workloads both from Facebook~\cite{} and
Twitter~\cite{} in order to model subscriptions. As mentioned in
Chapter~\ref{ch:vizpub}, the Facebook data trace include 3 million user
profiles along with 28.3 million friend relations. The Twitter dataset
consists of 41.7 million distinct users and 1.47 billion
follow/followed relations.

The social relations in Facebook are reciprocal, which leads us to model
bidirectional subscriptions. More specifically, a Facebook user is
modeled as a topic. The friends list of the particular user profile
constitutes its subscription list. All of the entries in this list will
include the original user in their own lists of subscriptions.
Relationships in Twitter however, are unidirectional. When using the
Twitter trace, users are also modeled as topics, but here the list of
subscriptions are formed on the basis of the ``following'' list of the
particular  user profile. The entries in this list are not required to
follow back, therefore subscriptions are also unidirectional.

Churn is based on the Skype super-peer trace from~\cite{}, tracing 4000
nodes for 4 weeks, tracking their joining and leaving timestamps. We
scale churn to include the first day of this trace in order to not
introduce a churn rate which is unrealistically high. For latency
between node pairs, we use the King dataset found in~cite{}.


\section{Results}

\subsection{Degree}

% \begin{figure}[H]
%     \centering
%     \input{eval_degree.tex}
%     \caption{Avg. Undirected degree of PolderCast and Scribe}
%     \label{fig:eval_degree}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \input{eval_indegree.tex}
%     \caption{Avg. In-Degree of PolderCast and Scribe}
%     \label{fig:eval_indegree}
% \end{figure}

\begin{figure}[H]
    \centering
    \thisfloatpagestyle{empty}
    \subfigure[Avg. In-Degree]{
        \input{eval_indegree.tex}
    }
    \subfigure[Avg. Out-Degree]{
        \input{eval_outdegree.tex}
    }
    \caption{Avg. Directed Degrees of PolderCast and Scribe}
    \label{fig:eval_directedtdegree}
\end{figure}

\subsection{Clustering Coefficient}
\begin{figure}[H]
    \centering
    \input{eval_cc.tex}
    \caption{Avg. Clustering Coefficient of PolderCast and Scribe}
    \label{fig:eval_cc}
\end{figure}

% \subsection{Centralities}

\begin{figure}[H]
    \centering
    \input{eval_betweenness.tex}
    \caption{Avg. Betweenness Centrality of PolderCast and Scribe}
    \label{fig:eval_betweenness}
\end{figure}

\begin{figure}[H]
    \centering
    \input{eval_closeness.tex}
    \caption{Avg. Closeness Centrality of PolderCast and Scribe}
    \label{fig:eval_closeness}
\end{figure}

\begin{figure}[H]
    \centering
    \input{eval_eccentricity.tex}
    \caption{Avg. Eccentricity Centrality of PolderCast and Scribe}
    \label{fig:eval_eccentricity}
\end{figure}

