In this chapter, we test the capabilities of  \demo{} as a framewor for
evalutating pub/sub systems. We extend the evaluation of PolderCast and
Scribe found in~\cite{Setty:2012} on a set of topology metrics. These
metrics are afforded to us for ``free'' by the Gephi framework through
the Statistics API included in the \emph{Gephi Toolkit}.

\section{\demo as a Framework for Evaluating Pub/Sub Systems}
\label{sec:viz_eval}

Although the plots seen in Chapter~\ref{ch:vizpub} are easy to produce
in Gephi, they are not very flexible. For example, it would be useful to
be able to superimpose two plots on top of each other in order to
effectively compare them. Therefore, in addition to outputting a \gexf
file which can be used to produce visualizations and plots in Gephi, The
collector is also able to generate \csv files which can be used to plot
a time series of metrics such as degree, clustering coefficient and
centralities. Each time point in the time series will represent a
\emph{Reporter Interval}. Although the Data Laboratory component in
Gephi is able to output such \csv files, it is much more convenient to
output them directly from the Collector, as opening the Gephi GUI-client
for the sole purpose of producing such files manually is more time
consuming, especially on older hardware, or machines without a dedicated
graphics card. The Collector is able to do this trough the Gephi
Toolkit, which provides an API for the major components of Gephi. Which
overlay properties to output is configurable in the Collector.
Currently, the supported metrics that can be exported to \csv files by
the Collector include:

\begin{itemize}
    \item Undirected Degree
    \item In-Degree
    \item Out-Degree
    \item Clustering Coefficient
    \item Betweenness Centrality
    \item Closeness Centrality
    \item Eccentricity Centrality
    \item Topic Diameter
    \item Size of Network
\end{itemize}

This grants researchers and developers of pub/sub protocols who wish to evaluate
the system in question immediate access to several metrics. They do not need to
reimplement algorithms for the metric calculations themselves. All that is
required is to implement the \emph{reporter interface}.

The plots produced aim at resembling the plots produced by the
Statistics Component in Gephi. However, due to using an external tool
for plotting, we can superimpose several plots on top of each other, as
well as adjust the format and layout of the plots. Also, it should be
noted that the output file format of the Gephi plots are non-vector
image files, which is not suitable for printing. The ability choose the
image format of the plots is another benefit over using the
standard plot output of Gephi.

\section{Experimental Restrictions}

As \demo{} is still is an early prototype state, there are restrictions
in terms the total number of nodes we can run as well as the number of
reporter intervals. This is due to the file sizes of temporary logs
grows linearly with the number of nodes, intervals and perhaps more
importantly: number of edges. This becomes problematic with pub/sub
systems which generate a high number of edges, such as PolderCast. The
Collector will also use a lot of memory when calculating custom metrics
due to loading these files in memory. Also, the Gephi Toolkit suffers
from performance issues due to an inefficient GEXF-parser. This means
that currently, \demo{} need a high amount of memory and disk space in
the order of several Gigabytes in order to operate properly.
Unfortunately, although we had access to the needed amount of memory, we
were restricted in terms of disk space. For this reason we restrict the
number of nodes and reporter intervals in our experiments.

The file sizes also grow linearly with the number of publication
messages. As the number of publication messages per interval can be in
the order of tens of thousands,  we evaluate only on topology metrics.
Also, due to time constraints we leave out the computational costly
\emph{topic diameter} metric, and leave this to future work.

We wish to improve the scalability of \demo{} in terms of file sizes in
the future, otherwise its usefulness for real deployed pub/sub systems
would be questionable at best. Luckily, there is a lot of low-hanging
fruits with regards to improving the performance in \demo{}. We describe
such future work in Chapter~\ref{ch:conclusion}.

\section{Experimental Setup}

We run PolderCast and Scribe in PeerNet using the simulation mode. The
Simulations consists of 1000 PeerNet cycles as well as 1000 reporter
intervals. We use workloads both from Facebook~\cite{facebook-eurosys09} and
Twitter~\cite{Kwak10www} in order to model subscriptions. As mentioned in
Chapter~\ref{ch:vizpub}, the Facebook data trace include 3 million user
profiles along with 28.3 million friend relations. The Twitter dataset
consists of 41.7 million distinct users and 1.47 billion
follow/followed relations.

The social relations in Facebook are reciprocal, which leads us to model
bidirectional subscriptions. More specifically, a Facebook user is
modeled as a topic. The friends list of the particular user profile
constitutes its subscription list. All of the entries in this list will
include the original user in their own lists of subscriptions.
Relationships in Twitter however, are unidirectional. When using the
Twitter trace, users are also modeled as topics, but here the list of
subscriptions are formed on the basis of the ``following'' list of the
particular  user profile. The entries in this list are not required to
follow back, therefore subscriptions are also unidirectional.

Churn is based on the Skype super-peer trace from~\cite{Guha:2006}, tracing 4000
nodes for 4 weeks, tracking their joining and leaving timestamps. We
scale churn to include the first day of this trace in order to not
introduce a churn rate which is unrealistically high. For latency
between node pairs, we use the King dataset found in~\cite{king}.

\section{Results}

\subsection{Degree}

% \begin{figure}[H]
%     \centering
%     \input{eval_degree.tex}
%     \caption{Avg. Undirected degree of PolderCast and Scribe}
%     \label{fig:eval_degree}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \input{eval_indegree.tex}
%     \caption{Avg. In-Degree of PolderCast and Scribe}
%     \label{fig:eval_indegree}
% \end{figure}

\begin{figure}[H]
    \centering
    \thisfloatpagestyle{empty}
    \subfigure[Avg. In-Degree]{
        \input{eval_indegree.tex}
    }
    \subfigure[Avg. Out-Degree]{
        \input{eval_outdegree.tex}
    }
    \caption{Avg. Directed Degrees of PolderCast and Scribe}
    \label{fig:eval_directedtdegree}
\end{figure}

\begin{figure}
    \centering
    \subfigure[Facebook] {
        \includegraphics[scale=0.3]{plots/scribe_edges_face}
    }
    \subfigure[Twitter] {
        \includegraphics[scale=0.3]{plots/scribe_edges_twitter}
    }
    \label{fig:scribe_edges}
    \caption{Plots describing the difference of number of edges in
        Scribe when using different subscription workloads.}
\end{figure}

\subsection{Clustering Coefficient}
\begin{figure}[H]
    \centering
    \input{eval_cc.tex}
    \caption{Avg. Clustering Coefficient of PolderCast and Scribe}
    \label{fig:eval_cc}
\end{figure}

% \subsection{Centralities}

\begin{figure}[H]
    \centering
    \input{eval_betweenness.tex}
    \caption{Avg. Betweenness Centrality of PolderCast and Scribe}
    \label{fig:eval_betweenness}
\end{figure}

\begin{figure}[H]
    \centering
    \input{eval_closeness.tex}
    \caption{Avg. Closeness Centrality of PolderCast and Scribe}
    \label{fig:eval_closeness}
\end{figure}

\begin{figure}[H]
    \centering
    \input{eval_eccentricity.tex}
    \caption{Avg. Eccentricity Centrality of PolderCast and Scribe}
    \label{fig:eval_eccentricity}
\end{figure}

