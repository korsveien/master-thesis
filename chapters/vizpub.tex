In this chapter we describe \demo~\cite{korsveien2014vizpub}, a tool we
propose for visualizing the performance of overlay-based Pub/Sub
Systems. In addition to describing the tool and its system architecture,
we present several examples of visualizations produced by using our
tool. Also, we use \demo{} in order to compare PolderCast and Scribe
visually, both using visualizations as well as using \demo{} in order to
produce certain plots. We also discuss the benefits of using
visualizations when studying and analyzing pub/sub systems, where we
share several experiences using our proposed tool.

We presented a poster and held a live demonstration of \demo{} at the
ACM International Conference of Distributed Event Based Systems (DEBS),
held in Mumbai in May 2014, where it was awarded the price for best
poster and demo. Also, our implementation of \demo{} is open source, and
available in a public repository.\footnote{\demo{} is open source and
    hosted at \url{http://github.com/vizpub/vizpub}} It is our hope that
our tool will be of benefit to the community, and aid researchers in further
development and study of overlay-based systems.

To the best of our knowledge, \demo~is the first tool of its kind. The
tool is able to visualize the execution of any given distributed pub/sub
system step by step with respect to a set of performance metrics. Each
node in the system records relevant data at selected intervals during
system execution. Our tool is then able to pull this data to a single
site, and compute various metrics at a system-wide scale. The collected
data from each interval is then collated into a single \gexf{} file,
which is interpreted by the \emph{Visualization Unit} which enable
replay of system execution offline.

Our tool supports two different types of visualizations: (1) visualization of the
overlay structure and how it evolves over time and (2) visualization of
publication message dissemination, where directed edges represent the
dissemination path. We provide examples of both types of visualizations
later in this chapter.

There are several benefits to using a tool such as \demo. It enables
researchers and developers to gain a deeper insight into the overlay
structure as well as the publication process. It also has major benefits
as an educational tool, as it provides students with a visual
representation of both the structural evolution of the system under
study, as well as a step-by-step animation of publication message
disseminations. This is useful in order to engage students, and to
facilitate deeper insight into the different pub/sub systems and their
dissemination schemes. Such an insight is also useful in order to
identify potential weaknesses or deployment anomalies of any given
pub/sub system. While developing our tool, we encountered many scenarios
where \demo{} demonstrated its usefulness. For example, when
experimenting with visualizations of PolderCast, we could immediately
verify that three nodes were disconnected at the RINGS layer, as seen in
Figure~\ref{fig:pold_disc}.  Using our tool, we were able to verify that
this was caused by an artefact in the input workload where the three
nodes had no overlapping interest with any other node in the overlay. We
were then able to confirm that the nodes were connected at the CYCLON
layer. We are not aware of any other tool or framework that would allow
such easy detection and validation of system behaviour.

\begin{figure}[h]
\includegraphics[width=\linewidth]{figures/disconnected-component-poldercast.pdf}
\caption{Visualization of disconnected component in the RINGS layer of PolderCast}
\label{fig:pold_disc}
\end{figure}

Another interesting use case for our tool is comparing different pub/sub
systems visually. Users may run the different systems using the same
system parameters as well as using the same workloads for subscriptions
and publications in order to replay the execution and then perform a
visual comparison. We include such a comparison in this chapter, were we
compare PolderCast and Scribe, in order to see what we can learn from
such a visual analysis.

\section{System Architecture}
\label{sec:arch}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figures/arch}
\caption{Architecture diagram of \demo}
\label{fig:arch}
\end{figure}

The architecture of \demo~consists of three main components, all
depicted in Figure~\ref{fig:arch}: (1) \emph{Reporter}, (2)
\emph{Collector} and (3) \emph{Visualization Unit}.  The arrows seen in
Figure~\ref{fig:arch} depicts the flow of data in the architecture.
Each node in the executing system consists of a pub/sub protocol as well
as a ``Reporter''. The Reporter is the entity responsible for providing
the raw information required to compute various performance metrics from
the individual nodes participating in the overlay. This information is
pulled at regular intervals to a central site by the ``Collector'',
which stores the information as a single file in the \gexf{} format.
This file is then interpreted by the ``Visualization Unit'', which
consists of a single machine running the \emph{Gephi Open Graph Viz
    tool}~\cite{ICWSM09154}. The Collector is designed to perform the
collection of data while in online mode, while the computation,
aggregation and derivation of various metrics is performed in offline
mode. The Visualization Unit always operate in offline mode, as all the
individual reports pulled from the different reporters needs to be
collated into a single \gexf{} file before it can be interpreted in Gephi
for playback and visualization. The processing of the individual reports
into this final report happens \emph{after} system execution.

\demo{} supports pub/sub systems that are deployed as
real distributed systems, as well as systems that are deployed in
simulation mode. This is due to the highly modular system architecture,
with strict separation of concerns, where the operation of both the
Collector and the Visualization Unit is kept separate from the reporting.

\demo~is also designed to be a generic tool, where the only system
specific part of the architecture is the \emph{reporter interface}
outlined in Table~\ref{table:interface}. Any researcher or developer who
wants to use our framework only needs to provide an implementation of
this interface, which enables the Collector to retrieve the relevant
data from each individual node by calling the methods of this
interface. The time points for collection are configurable, and all the
information collected from the Reporter can be thought of as a
representation of the change of system state from the current time point
to the previous time point with regards to the various performance
metrics. More specifically: the change of system state that occurred in
the \emph{interval} between two time points. Thus, we call these time
points \emph{reporter intervals}. The length of the intervals are
configurable, which provides the user with control over the granularity
of data collection, and thus the granularity of the step-by-step replay
of system execution performed in the Visualisation Unit. For example, if
running simulation using PeerNet, the user may determine whether or not
the reporter intervals should encompass several simulation cycles. Or,
in a real distributed pub/sub deployment scenario, the user can
determine the time delay between every reporter interval.


\subsection{Reporter}

The Reporter is responsible of providing the relevant data necessary in
order to calculate the desired performance metrics. In order to do so,
we specify a \emph{reporter interface} which must be implemented at each
individual node participating in the pub/sub overlay. This interface
enables each node to log certain system parameters using its local
knowledge at each reporting interval. This local information is then pulled
by the Collector at the end of each interval by invoking the
reporter interface. The available interface method calls and what data
they return is described in Table~\ref{table:interface}.

% ../tables/interface.tex
\input{tables/interface}

It is easy to see how certain performance metrics can be derived from
the methods listed in Table~\ref{table:interface}.  The structural
properties of the overlay such as \emph{degree}, \emph{diameter} and
\emph{clustering coefficient} can all be derived by reconstructing the
overlay topology and running the specific metric using the
\emph{Statistics Component} in Gephi. The reconstruction of the overlay
can be achieved  by collecting the information returned by the two first
methods listed in Table~\ref{table:interface}, namely
\texttt{reportId()} and \texttt{reportNeighborIds()}. For example, in
our reporter interface implementation for the RINGS layer in PolderCast,
each node returns its own id as well as the ids of both ring neighbors
and random neighbors. After this information is pulled, the Collector is
able to derive a graph structure where it first builds nodes based on
the information returned by \texttt{reportId()} and then draw directed
edges between these nodes based on the data returned from
\texttt{reportNeighborIds()}. What topics each node subscribe to is
also useful in order to derive and visualize metrics such as \emph{Topic
    Diameter} and \emph{Subscription Size}. The Collector is able to
pull information regarding topic subscriptions through the
\texttt{reportTopics()} method call. Each node will return a
set of topic ids, and the Collector is able to use this information to
attribute topics to nodes as well as edges.  In order to add topics
to edges, the Collector simply iterates through the topic id list of
each node, and looks for a neighbor who share a subscription to the same
particular topic: a \emph{topic neighbor}. If a topic neighbor of a node
is found, the topic id is added as an attribute to the edge connecting
them. Applying topic attributes to nodes and edges, provides the
Visualization Unit (i.e.\ Gephi) with the ability to strip away nodes
and edges that does not belong to a particular topic, thereby enabling
calculation of topic diameter.

The dissemination properties of a given pub/sub system such as
\emph{hit ratio}, \emph{path lengths}, and \emph{number of duplicate publication
messages sent/received} can be derived by having each node provide a list of
publication messages sent and received. In order to calculate these
dissemination metrics, the publication needs to have a particular
structure. This structure is described in Table~\ref{table:structure}.
For example, in order to calculate hit-ratio for a specific topic, we
need to divide the number of subscribers of that topic who actually
received the message with the total number of topic subscribers. We
already know which nodes subscribe to a particular topic through the
\texttt{reportTopics()} method call, and the list of publication
messages received by a node can be retrieved through
\texttt{reportPubMsgsReceived()}. Path length of a
message being published on a particular topic from a particular node may
be calculated in a similar fashion, as different copies of a publication message reported from
different nodes can be ordered based on their timestamp values.

The number of duplicate publication messages sent and received by each
node is available through the \texttt{reportControlMsgsSent()}  and
\texttt{reportControlMsgsReceived()} respectively, while the communication
overhead incurred by control messages in terms of bandwidth consumption can be
derived by the \texttt{reportControlBytesSent()} and
\texttt{reportControlBytesReceived()} method calls.

% ../tables/pubmessage.tex
\input{tables/pubmessage}

The structure of the publication messages outlined in
Table~\ref{table:structure} also allows for visualizing the paths of
publication messages. As mentioned, this is one of the two types of
visualizations the \demo{} is able to produce (where the other type is
the overlay structure). The Collector will output a separate \gexf{}
file for this type of visualization. When creating such a visualization,
the Collector will look at the topic id of the message, and only include
the nodes interested in the particular topic. The Collector will then
iterate through the messages sent and received by each node. By
analyzing the messages further, the Collector is able to create directed
edges between the nodes which represent the path of the publication
message. The edges are dynamic, i.e.\ they include a ``Time Interval''
attribute, enabling a step-by-step animation, where edges appear as the
animation is played back in Gephi. These edges trace
the path of the publication hop-by-hop. This enables researchers,
developers as well as students to analyze publication dissemination
schemes visually, which enhances their ability to understand, study and
debug dissemination algorithms.

In addition to being able to configure the reporter intervals, users of
\demo{} may choose to only report partial information. For example users
may choose to only report structural information such as node ids and
neighbor ids, or only dissemination specific data such as publication
messages sent and received. This flexibility is useful if only a few
aspects of system performance require analysis.

\subsection{Collector}
\label{sec:collector}

The Collector is the component responsible for pulling information from
the nodes at every reporting interval. It is also responsible for
aggregating and calculating certain \emph{custom metrics}. By custom, we
mean any metric that is not included in the \emph{Statistics Component}
of Gephi, described in Section~\ref{sec:viz_unit}. These metrics are
usually related to dissemination and include \emph{hit-ratio},
\emph{duplicate publication messages received} and \emph{path lengths}.
Metrics related to overlay structure can be calculated in Gephi. These
metrics include \emph{degree}, \emph{clustering coefficient},
\emph{diameter} and \emph{centralities}. There is one topology metric
which needs to be calculated in the Collector, namely \emph{Topic
    Diameter}. In order to calculate topic diameter, the graph needs to
be filtered down to a subgraph which only includes nodes and edges for a
given topic, then it must calculate the path length for every such
subgraph. Doing this manually using the Gephi GUI-client would be a time
consuming and error-prone task.  Therefore, the Collector takes
advantage of the \emph{Gephi Toolkit} in order to automate this task.

The Collector supports both what the Gephi community
refers to as \emph{static} and \emph{dynamic} metrics. This is also
referred to in literature and in~\cite{korsveien2014vizpub} as
\emph{instantaneous} and \emph{aggregated} metrics. In this thesis, we
will refer to them as static and dynamic, in order to be consistent
with the terminology used by the Gephi community. In short, static
metrics pertains to a specific point in time, while dynamic metrics are
based on historical values. The Statistics Component in Gephi includes
support for calculating both type of metrics, but dynamic metrics only include degree and
clustering coefficient, while the Collector is able to compute dynamic
metrics for all properties such as centralities, hit-ratio and number of
control messages sent and received.

Aggregation of data is performed by serializing each individual report
received from the reporters into temporary files which are stored on
disk. The Collector will then iterate through these files and output a
final report in the \gexf{} file format. This file can then be used to
create a range of visualizations, using the \emph{Visualization Unit}
described in Section~\ref{sec:viz_unit}. The \gexf{} file can be thought
of as a sort of ``replay'' file, which can be transferred to any other
computer running the \emph{Visualization Unit}. Storing the execution
of a pub/sub-system in a portable file grants researchers and developers
a high degree of flexibility which we believe is of great value. Users
of \demo{} may share this file between them, educators may make such
files available for students in order to study different pub/sub
protocols, and developers may share such files in order to aid each
other when debugging.

While collection of reporter data is done in online mode, aggregation is performed in
offline mode. The offline aggregation of data prevents the Collector
from acting as a bottleneck. Indeed, the collection and aggregation of
data is highly decoupled from the execution of the pub/sub protocol
itself. As an alternative, the Reporters are also able to log reports
locally, and push them to the Collector at the end of pub/sub execution.

The Collector will use the information pulled from the reporters in
order to apply attributes to nodes and edges. These attributes form the
basis of node labels and colors when visualized in Gephi. For
example, the number of control messages sent is a node attribute which
can be represented as a numeric label on nodes. Also Gephi will inspect
all nodes for their ``control messages sent'' attribute value, and
determine the maximum and minimum value. These value form a value range
which can be used to color the nodes on a gradient. For example, the
closer a nodes value is to the maximum, the deeper the color of the
particular node. Examples of visualizations using color can be seen in
Section~\ref{sec:examples}.

Some of the attributes are indirectly derived from the reported information, such
as the \emph{subscription size} of nodes, which is derived from the length of the
collection returned by \texttt{reportTopics()}. What attributes to apply
is configurable. The only edge attributes supported by the Collector is
the \emph{Topics} attribute. This is derived by determining the set of
subscribers of a topic and analyzing the edges between them. If two
nodes have an edge between them, they are topic neighbors. The list of
node attributes supported is far more extensive and includes:

\begin{itemize}
    \item Control messages sent
    \item Control messages received
    \item Control messages sent in kilobytes
    \item Control messages received in kilobytes
    \item List of topics subscribed to
    \item Number of topics subscribed to (i.e.\ \emph{Subscription Size})
    \item Number of duplicate publication messages received
\end{itemize}

These attributes describe data pertaining to individual nodes. However,
the Collector will also calculate data which is global to the entire
overlay. For example, the Collector is able to calculate averages such
as average control messages sent per interval. The Collector does this
by iterating through the interval range, and sum the numeric attribute
value of each node that exists in this interval before dividing this
number with the number of existing nodes, i.e.\ it calculates the
\emph{arithmetic mean} of each interval. The resulting averages are
applied to all nodes as labels, even though they represent a global
value, i.e.\ it is not a value specific to the particular node. This is
a workaround, as Gephi does not support displaying graph attributes.
The global attributes calculated by the Collector include:

\begin{itemize}
    \item Hit-Ratio
    \item Average Number of Control Messages Sent
    \item Average Number of Control Messages Received
    \item Average Number of Control Messages Received in kilobytes
    \item Average Number of Control Messages Received in kilobytes
\end{itemize}

The Collector is also able to calculate averages intended for plotting
time series using a tool such as \emph{gnuplot}, rather than be applied as a
node label. Adding support for these averages as node attributes is not
a priority at this point, but will be implemented in the near future. We
describe the supported calculations in Section~\ref{sec:viz_eval}, where
we further describe the use case intended for this feature of \demo.

\subsection{Visualization Unit}
\label{sec:viz_unit}

The \emph{Visualization Unit} is a machine running the Gephi Open Graph
Viz tool~\cite{ICWSM09154}. This tool is able to interpret the \gexf{} file generated by
the Collector and visualize the execution of the pub/sub system in
question. Gephi provides a rich GUI-experience where the user may
interact with the graph representation, apply layout algorithms, filter
the graph, execute metrics, apply color and size based on graph
properties and animate the graph evolving over time. The Gephi software
architecture is highly modular and supports extensions via plugins, some
of which are available in a official plugin
marketplace.\footnote{\url{http://marketplace.gephi.org}}. New metrics,
filters or added functionality such as database support may be
implemented through plugins by developers, and published to the
marketplace free of charge.

Gephi provides many tools and components which are useful when
inspecting and analyzing pub/sub overlays visually. These are what we
consider the most important components:

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/gui_ann}
    \caption{Snapshot of Gephi GUI with several important components
        annotated}
\end{figure}

\begin{description}

\item[Node Pencil and Edge Pencil Tools] \hfill \\

    These two tools enable the user to create nodes and edges by
    clicking in the graph view, which is the window where the nodes and
    edges are rendered. Edges can be directed or undirected,
    where direction is indicated with an arrow. These two tools combined
    enables building a graph by hand.

    Building such graphs can be useful in order to reason, analyze or
    learn network algorithms such as event dissemination algorithms.
    For example, the user can start with a single node which can act as
    the event source, and build the topology with directed edges which
    depict the path of the message. This is very helpful in fully
    understanding such algorithms and the trade-offs they make. The user
    can also add attributes to the nodes and edges either through the
    \emph{Node Query Tool} or in the \emph{Data Laboratory} component
    which also aids in visualising and understanding properties,
    as well as any drawbacks and advantages of such algorithms.

\item[Node Query Tool] \hfill \\

    \begin{figure}[h!]
        \centering
        \includegraphics[width=\linewidth]{figures/gui_node_query}
        \caption{The Node Query Tool opens a panel (to the left) that can be used to inspect the
            attributes of a node, here it is used to inspect the
            subscription size of a high-degree node}
        \label{fig:gui_node_query}
    \end{figure}

    With the Node Query Tool the user is able to click on a node in the
    graph view, and a panel will appear to the left with information
    regarding the \emph{properties} and \emph{attributes} of this node.
    Properties are data describing the visual parameters of the node
    such as size, position and color, while attributes include data such
    as node id, default label, the time intervals in which the node
    exists as well as any additional user defined attributes. In our
    case, examples of such user defined attributes would include topics,
    subscription size and number of control messages sent and received.
    The Node Query Tool can be seen in Figure~\ref{fig:gui_node_query},
    where it is used to inspect the \emph{subscription size} (i.e.\ number of
    topics the node subscribes to) of a high-degree node.

    Both the properties and attributes of the node are editable through
    the Node Query Tool. The user may select a property to change the
    visual representation of the node, or select an attribute in order
    to change its value. The \emph{Time Interval} attribute in
    particular is interesting to edit, as it represents the points in
    time in which a node exists in the graph view. For example, it could
    be interesting to edit the Time Interval attribute for certain
    nodes in order to see how it affects a particular metric as well as
    the structure of the overlay topology in general.

\item[Shortest Path Tool] \hfill \\

    With the shortest path tool selected, the user may click on two
    nodes in the graph view, and if there is a shortest path between
    them, this path will be highlighted with a color. This is useful in
    order to reason about the relationship between key nodes in the graph,
    or to compare shortest path between several pairs of nodes.

\item[Heat Map Tool] \hfill \\

    The \emph{Heat Map Tool} enables the user to click on a node in the
    graph view and color its neighborhood based on the edge weight distance between
    them. More specifically, it sets the node color intensity lower for more
    distant nodes and stronger for nodes that are closer. Edge weight is a
    standard edge attribute that is by default set to 1. This means that in
    the default case, the visualization will represent the hop count
    distance from the particular node selected by the user. However, the
    edge weight can be edited by the user in order to represent other
    properties of a system. For example, imagine setting the edge weight
    to represent network latency between two nodes. In this case, a
    neighboring node which is adjacent to the selected node would have a
    lower color intensity if the latency between them is higher than another
    neighboring node which is further away in terms of hop count.

\item[Timeline Component] \hfill \\

    The \emph{Timeline Component} introduces an animation scheme for
    temporal graphs. The user may choose playback parameters such as
    \emph{time interval size}, \emph{step size} and \emph{playback
        speed}. The Timeline will automatically filter out a subgraph
    defined by the upper and lower bound of the interval. The evolution
    of the dynamic graph will then be animated by moving these bounds by
    the distance defined by the step parameter. The delay between each
    step is decided by the playback speed.

    The Timeline enables the user to visually inspect the change in
    graph topology over time, as well as visualize and inspect node and
    edge attributes of the graph through both color, size and text
    labels which is able to change dynamically as part of the graph
    model animation. The Timeline also enables jumping to a specific
    point in time and investigating the corresponding subgraph and its
    properties by changing the upper and lower bound of the Time
    Interval.

\item[Statistics Component] \hfill \\

    \begin{figure}[h!]
        \centering
        \includegraphics[width=\linewidth]{figures/gui_statistics}
        \caption{The Statistics component is able to produce a HTML
            report which includes plots describing the distribution of
            values across the nodes}
        \label{fig:gui_statistics}
    \end{figure}

    The \emph{Statistics Component} enables graph topology analysis by
    executing metrics on the graph. There are two types of metric
    algorithms in Gephi: \emph{static} and \emph{dynamic}, where the
    former calculates a single value based on the currently defined time
    window, while the latter calculates a time series of values. When
    executing a dynamic metric, the user must define the time window
    size and tick. These parameters have the same functionality as the step parameter
    when using the \emph{Timeline Component}. When the metric executes, the
    time window will iterate through the entire time range of the
    simulation, calculating a value at each step. When finished,
    a time series is plotted and displayed for the user. Such reports
    are also generated and displayed when calculating static metrics. In
    the case of static metrics, scatter plots depicting the distribution
    of values are displayed, as seen in Figure~\ref{fig:gui_statistics}

    The Statistics component include several metrics which are relevant
    to pub/sub overlays. Useful static metrics include, but are not
    limited to:

    \begin{itemize}
        \item{Degree (In/Out/Avg./Max/Min/Distr.)}
        \item{Avg. Cluster Coefficient}
        \item{Centrality (Beetweeness/Closeness/Eccentricity)}
        \item{Average Path length}
        \item{Radius}
        \item{Network Diameter}
        \item{Number of Shortest Paths}
    \end{itemize}

    Out of these, only degree and the clustering coefficient metrics have dynamic
    versions, where both calculates the average value over time. The
    average for dynamic metrics are calculated by dividing the sum of
    all node attribute values with the total number of nodes in both
    cases.

\item[Ranking Component] \hfill \\

    \begin{figure}[h!]
        \centering
        \includegraphics[width=\linewidth]{figures/gui_ranking_table}
        \caption{The \emph{Ranking Table} (to the left) in the Ranking Component may
            be used to sort nodes by attribute value. In this
            screenshot it is used to rank nodes by degree in descending
            order.}
        \label{fig:ranking_table}
    \end{figure}

    The \emph{Ranking Component} is a key feature of Gephi which enables
    visualization based on node or edge attributes in form of color and
    size. When coloring nodes or edges, the ranking component will apply
    a gradient over the range of attribute values. The ranking component
    also include a ranking table, as seen in
    Figure~\ref{fig:ranking_table}, where the user may sort nodes based
    on the specified attribute value. This is useful for quickly finding
    the nodes with maximum and minimum value, which is a quick way of
    identifying bottlenecks in the system or potential load balancing
    issues.

    The Ranking Component also includes an auto apply feature, which
    supports visualising attributes dynamically while playing back the
    graph via the \emph{Timeline Component}. More specifically, the node labels and color
    will update with every step of the animation.

\item[Layout Component] \hfill \\

    The \emph{Layout Component} enables the user to execute algorithms that
    calculates the position of the nodes. The user is able to adjust the
    parameters of these algorithms in order to manipulate the visual
    layout. The different algorithms emphasize different aspects of the
    topology. One example is the so-named \emph{Force Atlas} layout algorithm which
    simulates the effect of gravity on the nodes, where linked nodes
    attract each other and non-linked nodes are pushed apart. This
    particular algorithm is useful for visually detecting clusters and
    communities. Another useful algorithm is the \emph{Circular Layout}
    algorithm, where nodes are positioned in a circle ordered on a
    specific node attribute selectable by the user. This is useful in order
    to visualize node rankings on particular attributes. We use the
    circular layout extensively, as nodes in PolderCast are organized
    into a ring structure, where they are ordered by their unique id.

\item[Filter Component] \hfill \\

    \begin{figure}[h!]
        \centering
        \includegraphics[width=\linewidth]{figures/gui_filter}
        \caption{The Filter Component (to the right) enables users to strip away
            unwanted nodes and edges, in this screenshot it is used to
            display the sub-overlay for a specific topic by using a
            \emph{regular expression}.}
        \label{fig:ranking_table}
    \end{figure}

    \emph{Filters} may be applied to the graph in order to strip away
    nodes or edges on the basis of their attributes. Filters may strip
    away nodes based on a value range if the attribute type is a number,
    or they can be matched on a regular expression if the attribute is
    encoded as a string. Filters can also be combined through special
    operator filters representing set operations such as union and
    intersect.

    Filters are an essential mechanism in order to analyze subgraphs.
    For example, in order to calculate \emph{topic diameter} in pub/sub systems,
    a subgraph can be filtered out based on a \emph{topic attribute}. Then, the
    diameter metric can be executed on this subgraph, which will result
    in the diameter of the particular topic.

\item[Data Laboratory Component] \hfill \\

    \begin{figure}[h!]
        \centering
        \includegraphics[width=\linewidth]{figures/gui_data_lab}
        \caption{The Data Laboratory Component provides a table overview
        of metrics as well as the capability of exporting data.}
        \label{fig:data_lab}
    \end{figure}

    The \emph{Data Laboratory Component} enables the user to work with
    the node and edge attributes of the graph. This component provides
    the user with separate table views of node and edge attributes, as
    seen in Figure~\ref{fig:data_lab}. Each row in this table represent
    a node or edge, and each column an attribute. Columns may be added
    or removed by the user. The Data Laboratory also provides
    functionality for manipulating columns such as merging two columns
    or creating new columns based on the data from selected columns.
    Attribute data in columns that are static (i.e.\ has no lower or
    upper time interval bound associated with them) can be converted to
    dynamic through this component. Also, resizing or coloring all edges
    or nodes is possible through the laboratory by selecting all rows
    and right-clicking. In addition to this, the Data Laboratory also
    enables the user to export the data to file for further statistical
    analysis.

\end{description}

\section{Examples of Visualizations}
\label{sec:examples}

In this section, we present a number of visualization produced by \demo.
The examples we provide in this section include both visualizations of
overlay structure as well as hop-by-hop message dissemination.  We
implement a reporter interface both for PolderCast as well as Scribe and
provide examples of visualizations for both protocols where we also compare them
visually on various performance metrics. Both protocols are implemented
using the PeerNet P2P simulator by updating existing PeerSim
implementations of Scribe and PolderCast.

Many of these visualizations were part of our demonstration at
DEBS 2014, and should provide some insight the benefits of using
our tool, and what sort of possibilities there are in terms of
visualizing overlays.

\subsection{Data Traces Used in Simulations}

We use publicly available datasets from
Facebook~\cite{facebook-eurosys09} and Twitter~\cite{Kwak10www}. The
Facebook dataset consists of 3 million user profiles along with 28.3
million social relations between these users. The Twitter dataset
consists of 41.7 million distinct user profiles and 1.47 billion
follow/followed relations. In both datasets users are modeled as topics.
In the Facebook dataset, subscriptions are modeled after the friends
list of the particular user. As relationships in Facebook are
bidirectional, two topics will subscribe to each other. In Twitter,
relationships are unidirectional, as users may choose to follow other
users, but no user who is followed need to reciprocate. As a user is
modeled as a topic, its list of followers are modeled as the subscribers
of that topic.

Churn is based on the Skype super-peer network data
trace~\cite{Guha:2006}, where 4000 nodes are tracked for joining and
leaving timestamps for one month staring on September 12, 2005. Finally,
we use the King dataset~\cite{king} in order to model latency between
nodes.

\subsection{Overlay Evolution During Churn}
\label{sec:churn}

\afterpage{\clearpage}
\begin{figure*}[H]
    \vspace{-80pt}
    \centering
    \thisfloatpagestyle{empty}
    \includegraphics[scale=0.5]{figures/churn_0}
    \caption{Overlay structure of PolderCast at interval 0}
    \label{fig:churn0}
    \includegraphics[scale=1]{figures/churn_250}
    \caption{Overlay structure  of PolderCast at interval 250}
    \label{fig:churn250}
    \includegraphics[scale=1]{figures/churn_500}
    \caption{Overlay structure of PolderCast at interval 500}
    \label{fig:churn500}
\end{figure*}

In Figure~\ref{fig:churn0},~\ref{fig:churn250} and~\ref{fig:churn500} we
visualize the overlay topology of 2000 PolderCast nodes during churn.
This is one of the examples of visualizations we presented at DEBS 2014.
Each figure describes the structure of the overlay at different reporter
intervals. Figure~\ref{fig:churn0}
depicts the overlay at interval 0, where 132 nodes are up while the
remaining 1868 are down due to churn. The snapshot in
Figure~\ref{fig:churn250} depicts the overlay at interval 250, after a
considerable number of nodes have joined the network. More specifically,
interval 250 consists of 1028 nodes, which means 896 nodes joined in the
interim. It is also possible to observe the edges evolve over time. While the first interval consisted
of 108 edges, interval 250 consists of 1028 edges. It is interesting to
look at how the edges evolve, as they provide us with
immediate visual feedback on properties such as clustering of nodes,
graph density and node degree. Such properties can then be further
analyzed using the Statistics Component in Gephi.

Visualizations of overlay structure also provide immediate information
regarding the dataset being used. As mentioned, we encountered a
scenario where an artefact in the dataset resulted in a disconnected
component in the visualized overlay. Here we notice that many of the
nodes are disconnected. This is due to a sampling bias, as the
particular Facebook dataset sample used for this visualization contains
10,000 nodes while the simulation runs 2000 nodes. However,
visualizations including a high number of nodes is not appropriate for
print due to space restrictions, also visualizing a high number of nodes
require more graphics rendering power than what we had available at the
time. The visualization still serve as an example of revealing both
properties of the overlay, as well as properties of the workload sample
being used, and any potential biases included in it.

\subsection{Visualizing Performance Metrics}
\label{sec:viz_perf}

\demo{} supports visualizations of a number of performance metrics.
These metrics are applied as attributes to both nodes and edges. The
supported metrics are listed in Section~\ref{sec:collector}. In Gephi,
we can visualize these metrics by applying the corresponding attribute
as a node label as well as use the \emph{Ranking Component} in order to
apply color to the nodes. Such visualization can be seen in
Figure~\ref{fig:avg_ctrl} which shows the average number of control
messages being sent and received for each node in PolderCast. This visualization can
be produced using the same \gexf{} file as the one which is used for
creating the visualization of overlay structure during churn seen in Section~\ref{sec:churn}.

Applying colors helps in discovering potential bottlenecks by highlighting
overloaded nodes. Both the node labels and node colors will update during
playback of system execution. As the control message metrics are running
totals, the user will observe the nodes getting a deeper color towards
the end of the playback. Users can choose the pause the animation any
time they like, as well as jump to any point in time. The user is then
able to inspect the overlay, run metrics using the \emph{Statistics
    Component} as well as produce plots as seen in
Section~\ref{sec:comparing}. The user may also export data to a \csv
file using the \emph{Data Laboratory} for further statistical analysis.

\begin{figure}[Ht]
    \centering
    \subfigure[Average number of control messages \bf sent]{%
    \includegraphics[scale=0.35]{figures/msg_sent_avg}
}
    \subfigure[Average number of control messages \bf received ]{%
    \includegraphics[scale=0.35]{figures/msg_rcv_avg}
}
\caption{Visualizations of average number of control messages sent and
    received per node in PolderCast}
\label{fig:avg_ctrl}
\end{figure}

\subsection{Publication Message Dissemination}
\label{sec:dissviz}

In subsection~\ref{sec:churn} we illustrate one of the two types of
visualizations it is possible to produce by leveraging \demo, namely
visualizations of overlay structure. Here we will describe the second:
visualization of publication message dissemination.

We run a PeerNet simulation in distributed mode with 100 nodes running
the PolderCast protocol with a fanout set to $f=2$. In order to scale
the experiment, the simulation includes 10 machines, where each machine
is running 10 PeerNet nodes. We publish a single message on the
most popular topic which includes 63 subscribers. By analyzing copies of
the publication message received on each node, the Collector is able to
create a step-by-step visualization where directed edges are drawn as
the message is disseminated through the overlay. These edges depict the
path of the message being disseminated. The visualization includes 189
edges in total, which indicates how many publication messages was sent
by all nodes during the simulation.

Figure~\ref{fig:diss_1} is a visualization of the dissemination in
PolderCast after 1 and 4 hops, while~\ref{fig:diss_2} are snapshots of
the visualization after the dissemination has finished.  The nodes have
been arranged in a ring using the \emph{Layout Component} in Gephi. Also
they are ordered by node id, making it easier to see whether an edge
represent a ring link or a random link. The labels indicate the hop
number of the message received by that node. On the left side of the
ring in Figure~\ref{fig:diss_1} and Figure~\ref{fig:diss_2 } there is a
node with the label ``0'', which indicates that this is the publishing
node. A node with the label ``1'', means the node received a message at
the first hop, a node with a label ``2'' that it received a message at
the second hop, and so on. In addition to numeric labels, the nodes are
color coded on a gradient. The deeper the color of the node, the higher
the hop count, which also means it is further away from the publisher. In
Figure~\ref{fig:diss_2} the node furthest away is easily spotted on the
left by its deep red color. This is the last node to receive the
publication.

It might seem strange that the last node to receive the message is an
immediate ring neighbor of a node who received the message on the first
hop. Observe that in Figure~\ref{fig:diss_1} this neighboring node who
received a message on the first hop does indeed send a message to the
node in question. However, in Figure~\ref{fig:diss_2}, which depict the
dissemination after the message has been sent, no numeric label is
applied to the node. This could give the impression that this node did
not receive any message. However, this is not the case. The explanation
behind this is latency. The latency between these two nodes is so high
that by the time it received the message from its ring neighbor, the
message was already received from another node. We choose to visualize
this by drawing an edge to the node and then refrain from applying a
numeric label. When we reach the point in the animation where this node
receives a message for the first time, we apply the hop count of this
message as a numeric node label.

\afterpage{\clearpage}
\begin{figure}[H]
    \vspace{-90pt}
    \thisfloatpagestyle{empty}
    \centering
    \thisfloatpagestyle{empty}
    \subfigure[After 1 hop]{%
    \includegraphics[scale=0.65]{figures/diss_1}
}
\subfigure[After 4 hops]{%
    \includegraphics[scale=0.65]{figures/diss_2}
}
\caption{Visualization of publication message
    dissemination in PolderCast.}
\label{fig:diss_1}
\end{figure}

\afterpage{\clearpage}
\begin{figure*}[h]
    \vspace{-90pt}
    \thisfloatpagestyle{empty}
    \includegraphics[scale=0.65]{figures/diss_3}
    \caption{Visualization of PolderCast after the end of dissemination}
    \label{fig:diss_2}
    \includegraphics[scale=0.65]{figures/diss_dup_msg}
    \label{fig:dups}
    \caption{Visualization of duplicate publication messages received by
    each node in PolderCast}
\end{figure*}

When inspecting the dissemination algorithm of protocols visually,
implementation details which could otherwise be overlooked become easily
detectable. For example, in Figure~\ref{fig:diss_1} it can be observed
that the publisher node sends a message to four nodes, even though the
fanout is set to $f=2$. This fanout indicate that the node
should send the message to three neighbors, based on the description of
the dissemination algorithm of PolderCast, summarized in
Chapter~\ref{ch:background}. However, there is an implementation detail
in PolderCast that is not mentioned in the original
paper~\cite{Setty:2012}. In the implementation of the PolderCast
protocol, publishers send messages to one additional random node in
order to boost the initial phase of the dissemination. Learning such
implementation details is useful to both researchers and developers, and
it is especially useful for students. We believe \demo can be very
valuable as an educational tool, as its grant students with the
capability of controlling the dissemination by using the Timeline
Component in Gephi. Students may pause the visualization at any point in
time or jump to any step of the visualization in order to fully
understand the benefits and drawbacks of the particular dissemination
scheme being studied.

It is also useful to create such visualizations in order to discover
issues or bugs with the dissemination algorithm. As observed in
Figure~\ref{fig:diss_1}, the publisher disseminates to four nodes, where
two of these should be random neighbors. However, the publisher
seemingly sends the message to three of its closest ring neighbors.
This means a neighbor close to it have been chosen as a random neighbor.
This might indicate a bug in the CYCLON module of PolderCast, which is
responsible of providing the RINGS layer with uniform random neighbors.
However, the dissemination happens at an early point of the experiment,
more specifically, after 50 PeerNet cycles. Due to experimental
settings, this might not have been enough time for the different layers
of overlays in PolderCast to converge. Also, it could be a special case,
which resulted in the publisher being a bit ``unlucky'' when picking a
random neighbor in this particular scenario. Regardless, visualizing
dissemination leads to these types of interesting observations, which
might lead to even more interesting findings with regards to protocol
behaviour. For example, one such interesting observation is how a fanout
of $f=2$ leads to a special case when disseminating messages in
PolderCast. More specifically, as mentioned in
Chapter~\ref{ch:background}, a node running PolderCast will forward a
message to both ring neighbors and $f-2$ random neighbors if it received
a message through a random link.  But if $f=2$, then the number of
random neighbors would be zero, since $f-2 = 0$. However, PolderCast
will always include a minimum of one random link when it forwards a
message. This is yet another implementation detail which could be hard
to catch without being able to inspect the dissemination protocol
visually.

One of the trade-offs we mention in Chapter~\ref{ch:design-challenges}
is the one between the number of duplicate messages received and the
robustness of message delivery. In Figure~\ref{fig:diss_2} we can
quickly confirm visually that some of the nodes have a high degree. This
indicates that the number of duplicate messages this these nodes
received is high. A certain number of duplicate messages in epidemic
dissemination is to be expected, but a balance should be struck between
number of duplicate messages and reliable delivery. If there are too
many unnecessary messages being sent, scalability in terms of bandwidth
suffers.

Deriving the exact number of duplicate messages received by each node is
trivial. As each directed edge represent a message being sent, all we
need to do is calculate the in-degree of each node using the Statistics
Component in Gephi. The result can be seen in Figure~\ref{fig:dups}.
This visualization indicate that PolderCast does indeed introduce a
rather high number of duplicate messages being received on each node.
However, it is only an indication and nothing more as this visualization
traces a single publication message on a single topic. We should not use
this observation to make any sweeping conclusions regarding the general
case. However, such an indication can be useful in order to guide
researchers and developers towards potential issues or bugs. We believe
\demo is a useful tool in this aspect.

\subsection{Comparing Pub/Sub Systems Visually}
\label{sec:comparing}

In Figure~\ref{fig:struct} we visualize the structure of PolderCast and
Scribe. We run PeerNet experiments in simulation mode, consisting of
1000 nodes, 1000 reporter intervals and 1000 PeerNet cycles.
Subscriptions are modeled after the Facebook dataset found
in~\cite{facebook-eurosys09}. The resulting \gexf{} files are imported into Gephi
in order to analyze the overlay structure both visually as well by
calculating certain metrics using the \emph{Statistics Component}. The
calculated values are described in Table~\ref{tab:struct_metrics}. The
from \emph{Number of Nodes} and \emph{Number of Edges} which are totals,
while the other values are averages across the duration of the experiment.

\begin{table}[h!]
    \centering
    \begin{tabular}{|l | l | l |}
        \hline
        & PolderCast & Scribe \\ \hline
        \hline
        Total Number of Nodes & 833 & 833 \\ \hline
        Total Number of Edges & 18629 & 883 \\ \hline
        Average Degree & 22.36 & 1.06 \\ \hline
        Average Graph Diameter & 10 & 22 \\ \hline
        Average Path Length & 2.96 & 8.9 \\ \hline
        Average Graph Density & 0.027 & 0.001 \\ \hline
        Weakly Connected Components & 63 & 280 \\ \hline
        Strongly Connected Components & 83 & 623 \\ \hline
        Average Clustering Coefficient & 0.369 & 0.003 \\ \hline

    \end{tabular}
    \caption{Calculated metric values for PolderCast and Scribe, calculated using
        the \emph{Statistics Component} in Gephi.}
    \label{tab:struct_metrics}
\end{table}

Inspecting the overlay structure visually enables us to derive certain
information which can guide us in further investigations. For example,
by visually comparing the two overlays in Figure~\ref{fig:struct}, we
can observe that the overlay of PolderCast seem to include a lot more
edges, as well as being more dense than the overlay in Scribe. Both
these visualization consists of 362 nodes, but the PolderCast overlay
seen in Figure~\ref{fig:polder_struct} consists of 2307 edges, while the
Scribe overlay, seen in Figure~\ref{fig:scribe_struct} consists of 193
edges. The overlay in PolderCast has almost twenty times the number of
edges. This is consistent with the total number of edges across the
duration of the experiment seen in Table~\ref{tab:struct_metrics}. The
higher number of edges should also mean PolderCast also has a much
higher average degree as well as a higher graph density. Executing these
metrics using the Statistics Component reveal that PolderCast indeed
have a much higher degree, again almost twenty times that of Scribe. The
\emph{graph density} is also much higher in PolderCast. Graph density is
measured as how far away the graph is to being complete, where 1 is a
complete graph. The lower density of Scribe is a natural consequence of
the lower number of edges. The difference in edge count is due to the
average node degree having a lower upper bound in Scribe, as described
in Chapter~\ref{ch:design-challenges}. More specifically, the average
node degree in Scribe is bound by the logarithm of the number of nodes
in the overlay $O(log |\mathcal V|)$, while in PolderCast it is in the
order of the number of subscriptions $O(|\mathcal T_v|)$. The
visualization allows us to observe this difference for ourselves.

\afterpage{\clearpage}
\begin{figure}
    \vspace{-100pt}
    \thisfloatpagestyle{empty}
    \subfigure[PolderCast]{%
        \includegraphics[scale=0.67]{figures/polder_structure}
        \label{fig:scribe_struct}
    }
    \subfigure[Scribe]{%
        \includegraphics[scale=0.67]{figures/scribe_structure}
        \label{fig:polder_struct}
    }
    \caption{Visualizaton of the \textbf{overlay
            strucure} of PolderCast and Scribe after 1000 intervals}
    \label{fig:struct}
\end{figure}

\afterpage{\clearpage}
\begin{figure}
    \centering
    \vspace{-100pt}
    \thisfloatpagestyle{empty}
    \subfigure[PolderCast]{%
        \includegraphics[scale=0.67]{figures/polder_degree}
        \label{fig:polder_degree}
    }
    \subfigure[Scribe]{%
        \includegraphics[scale=0.67]{figures/scribe_degree}
        \label{fig:scribe_degree}
    }
    \caption{Visualization of \textbf{degree} in
        PolderCast and Scribe after 1000 intervals}
\end{figure}

The fact that the number of edges in PolderCast is much higher, also
means the overlay is better connected. This is evident if we look at the
number of connected components. Strongly connected components have a
directed path between every pair of nodes, while weakly connected
components are connected through undirected edges. As seen in
Table~\ref{tab:struct_metrics}, the Scribe overlay is more partitioned,
as it includes a higher number of graph components, both strongly
connected as well as weakly connected. The higher number of graph
components in Scribe is likely due to the topics being organized into
separate dissemination trees, where the paths between the rendezvous
nodes are connected at the DHT layer. Also, disconnected nodes are
caused by subscribers not having any topic neighbors online due to
churn. In fact, the fast churn of the experiment might have had an
detrimental effect on Scribe, as it relies on tree structures which are more
brittle and in need of constant repair when facing a high degree of
churn. But this illustrates one of the difficulties designers of such
pub/sub systems face: how do you balance robustness of the overlay while
maintaining a low node degree. The two visualizations in
Figure~\ref{fig:struct} should serve as examples of two different
approaches to this question.

Note from Table~\ref{tab:struct_metrics} that both the average diameter
as well as path length is shorter in PolderCast than in Scribe. This is
a natural consequence of a higher number of edges. It indicates a better
connectivity in PolderCast, which is beneficial in terms of message
dissemination.

Looking at the overlay structures in Figure~\ref{fig:struct} also
indicate that some nodes are overloaded. The PolderCast overlay in
particular seems to have a very overloaded node in terms of degree,
visible in the upper middle of Figure~\ref{fig:polder_struct}. Using the
capabilities of \demo{}, we are able to look further into the issue of
load balancing. Figure~\ref{fig:polder_degree} and
Figure~\ref{fig:scribe_degree} visualize the degree of the nodes in the
overlay by color. The deeper red the color of the node is, the higher
its degree. This is useful for spotting potential bottlenecks in the
system, as well as getting a general overview of the degree
distribution. We can immediately observe that Scribe seems to have a
more even distribution of color, which implies a better distribution of
degree. But in order to determine the specific values, we need more than
a colored graph. One option is to apply the degree value to each node as
a text label. However, we skip this option as it is not suitable for
print. But in a scenario where the researcher explores the overlay on a
computer screen, this is a useful way of quickly determining attribute
values of nodes. Luckily, the Statistics Component in Gephi includes the
option of displaying scatter plots of degree distribution, as well as
storing these plots to the hard drive as image files.
Figure~\ref{fig:polder_degree_distr} and
Figure~\ref{fig:scribe_degree_distr} describes the undirected degree
distribution of PolderCast and Scribe. Note that these values are
averages across the duration of the experiment, while the visualizations
found in Figure~\ref{fig:struct} only represents the structure of the
overlay at interval 1000. Looking at the distributions in
Figure~\ref{fig:polder_degree_distr}
and~\ref{fid:polder_degree_distr},we can see that both are skewed to the
right. However, the range of values are more tightly bound in Scribe,
indicating a fixed degree. As mentioned, PolderCast has a average node
degree proportional to the number of subscriptions, which results in a
larger range of values than what is seen in Scribe. In fact, by using
the \emph{Rank Table} in Gephi, we can quickly find the maximum node
degree in the overlay at interval 1000, which can server as an
indication of the difference in node degree. Doing this, we find that in
PolderCast the maximum node degree at interval 1000 is 648, while in
Scribe it is 193.

The high-degree node found in the PolderCast overlay in
Figure~\ref{fig:polder_struct} might indicate that this particular node
has a much higher number of subscriptions then the other nodes in the
overlay. We can confirm this suspicion by using the \emph{Node Query
    Tool}, which shows us that this particular node subscribes to 466
topics, which is is 418 topics more than the node which is ranked second
in terms of subscription size. This is consistent with the way degree
grows with the subscription size in PolderCast. Scribe might have an
advantage in terms of node degree if there are many nodes in the system
with a high number of subscriptions. The same node in Scribe, seen at
the middle of the overlay in Figure~\ref{fig:scribe_struct}, has node
degree of 12.

Figure~\ref{fig:polder_indegree_distr},~\ref{fig:polder_outdegree_distr},~\ref{fig:scribe_outdegree_distr}
and Figure~\ref{fig:scribe_outdegree_distr} describes the distribution
of average directed degree across the duration of the experiment per
node in PolderCast and Scribe. Both in PolderCast and Scribe the
distribution of in-degree and out-degree seems to be quite balanced and
both distributions seem to have a long tail. However, there seems to be
an outlier in the PolderCast distributions, which would represent a node
with a very high average node degree. If we look back at the undirected
distribution found in Figure~\ref{fig:polder_degree_distr}, we can
barely make out this outlier in the far right of the plot, although it
is difficult to spot.  Unfortunately, Gephi does not provide any options
for configuring these plots, otherwise we could be able to increase the
range of the x values in order to see this data point properly.

\begin{figure}[Ht]
    \centering
    \includegraphics[scale=0.5]{plots/polder_nodes_ts}
    \label{fig:polder_node_ts}
\end{figure}

In addition to inspecting degree distribution, Gephi also provides us
with the possibility of plotting time series. These are produced after
executing the \emph{dynamic} metrics in the Statistics Component.  The
time series can tell us additional information regarding the evolution
of the overlay structure. We can easily produce a chart plotting the
network size, i.e.\ the number of nodes in the overlay, as seen in
Figure~\ref{fig:polder_node_ts}.  Here, a spike in the number of nodes
joining the network can be seen around interval 100. The effect of this
spike is easily observed in most of the plots in Figure~\ref{fig:ts}.
Naturally, the number of edges also increase sharply at this point in
time, as seen in Figure~\ref{fig:polder_edges_ts} and
Figure~\ref{fig:scribe_edges_ts} as well as degree seen in
Figure~\ref{fig:polder_degree_ts} and Figure~\ref{fig:scribe_degree_ts}.
Note that the average degree in Scribe drops at around interval 350,
where many nodes leave the network. This is not the case in PolderCast,
where the average node degree fluctuates less than in Scribe. This yet
again indicates that Scribe is more vulnerable to churn. However, in
both overlays the number of edges drop around interval 400, where a lot
of nodes are down due to churn. Still the node degree in PolderCast
remains stable. This might serve to illustrate the robustness of the PolderCast overlay.

The robustness of the PolderCast overlay compared to Scribe also seems
evident when plotting the time series for the clustering coefficient of
the overlay as seen in Figure~\ref{fig:polder_cc_ts} and
Figure~\ref{fig:scribe_cc_ts}. The average clustering coefficient in
PolderCast is not just much higher, but also much more stable. The low
clustering coefficient in Scribe might be due to the construction of
dissemination trees.

Note that the visual analysis performed in this section is not intended as a
full blown comparison of PolderCast and Scribe, but it should serve as
an indication of how useful and convenient it can be to perform such a
visual comparison of two protocols. Using both the \emph{Statistics
    Component} in Gephi in order to produce plots, as well as producing
visualizations of the overlays leads to several interesting observations
which can lead the researcher on a path of further investigations and a
more thorough evaluation.

\newgeometry{left=0cm, right=0cm}
\begin{figure}[H]
    \thisfloatpagestyle{plain}
    \centering
    \subfigure[PolderCast]{%
        \includegraphics[scale=0.4]{plots/polder_degree_distr}
        \label{fig:polder_degree_distr}
    }
    \subfigure[Scribe]{%
        \includegraphics[scale=0.4]{plots/scribe_degree_distr}
        \label{fig:scribe_degree_distr}
    }
    \subfigure[PolderCast]{%
        \includegraphics[scale=0.4]{plots/polder_indegree_distr}
        \label{fig:polder_indegree_distr}
    }
    \subfigure[Scribe]{%
        \includegraphics[scale=0.4]{plots/scribe_indegree_distr}
        \label{fig:scribe_indegree_distr}
    }
    \subfigure[PolderCast]{%
        \includegraphics[scale=0.4]{plots/polder_outdegree_distr}
        \label{fig:polder_outdegree_distr}
    }
    \subfigure[Scribe]{%
        \includegraphics[scale=0.4]{plots/scribe_outdegree_distr}
        \label{fig:scribe_outdegree_distr}
    }
    \caption{Degree distribution of PolderCast and Scribe, produced
        by the \emph{Statistics Component} in Gephi.}
\end{figure}
\restoregeometry


\newgeometry{left=0cm, right=0cm}
\begin{figure}[H]
    \thisfloatpagestyle{plain}
    \centering
    \subfigure[PolderCast]{%
        \includegraphics[scale=0.4]{plots/polder_edges_ts}
        \label{fig:polder_edges_ts}
    }
    \subfigure[Scribe]{%
        \includegraphics[scale=0.4]{plots/scribe_edges_ts}
        \label{fig:scribe_edges_ts}
    }
    \subfigure[PolderCast]{%
        \includegraphics[scale=0.4]{plots/polder_degree_ts}
        \label{fig:polder_degree_ts}
    }
    \subfigure[Scribe]{%
        \includegraphics[scale=0.4]{plots/scribe_degree_ts}
        \label{fig:scribe_degree_ts}
    }
    \subfigure[PolderCast]{%
        \includegraphics[scale=0.4]{plots/polder_cc_ts}
        \label{fig:polder_cc_ts}
    }
    \subfigure[Scribe]{%
        \includegraphics[scale=0.4]{plots/scribe_cc_ts}
        \label{fig:scribe_cc_ts}
    }
    \caption{Time series of PolderCast and Scribe, produced
        by the \emph{Statistics Component} in Gephi.}
    \label{fig:ts}
\end{figure}
\restoregeometry




\section{Implementation Work}

During our implementation work, we encountered several scenarios were
\demo proved its usefulness as a tool for both developing and debugging
pub/sub protocols. In this section, we will describe some of these
experiences, as well as experiences with other aspects of software
development and distributed systems research such as using test-driven
development and sharing code with the research community.

\subsection{Using Visualizations to Analyze Datasets}

In the beginning of this chapter we mention how we were able to observe a
disconnected component in the RINGS layer of PolderCast, as seen in
Figure~\ref{fig:pold_disc}, and later confirm this was an artefact of
the workload being used. More specifically, we used the \emph{Node Query
    Tool} in Gephi to ensure these nodes had zero overlapping
subscriptions with any other node in the overlay by inspecting the
``Topics'' attribute of the visualized nodes. This was the first
practical experience we had with the tool, were it usability was clearly
demonstrated. It speaks to how visualizations are also able to provide
information of the datasets being used. In the scenario we describe, we
used a real-world trace from Twitter~\cite{Kwak10www}, which included
1000 user accounts and their subscriptions. However, the PeerNet
simulation only included 100 nodes for testing purposes. This lead to a
biased sample of the trace, which in this case resulted in a
disconnected component. Being able to run simulations with fixed
parameters but different datasets, and then inspect the resulting
overlay visually is another aspect of using \demo which should prove
useful for researcher of topic-based pub/sub systems.

\subsection{Debugging Pub/Sub Systems Visually}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\linewidth]{figures/hitratiobug}
    \caption{Visualization of a fully connected dissemination graph in
        PolderCast, which revealed a bug in the implementation of hit-ratio
        calculation}
   \label{fig:hitratiobug}
\end{figure}

When implementing hit-ratio calculation in the Collector, producing a
visualization of the publication message dissemination revealed a bug in the implementation code.
In PolderCast, the hit-ratio in the absence of churn should be 100\%.
However, the Collector would consistently calculate the hit-ratio to
97\%. Usually, the first step in debugging such issues is to isolate the
problem. In this case, there could be a software bug in the
implementation of the pub/sub protocol itself, or the bug might be in
the implementation of the hit-ratio calculation. Using \demo, we were
able to quickly isolate the problem. By producing a visualization of the
publication message dissemination, seen in Figure~\ref{fig:hitratiobug},
we were able to visually confirm that all nodes that took part in the dissemination
received the message. Furthermore, we could confirm this observation by
using the Statistics component in Gephi, which enables calculation of
the number of connected components in the graph.  The calculation
revealed that the graph is a single strongly connected component, i.e.\
from any node in the graph there is a directed path to any other node.
This means that every node received the publication. However, the
Collector still calculated the hit-ratio to 97\%. This indicates that
the problem is not with the implementation of the protocol, but with the
implementation of the hit-ratio calculation. And indeed, by inspecting
the hit-ratio calculation in the Collector, we revealed a
\emph{off-by-one} software bug, leading to incorrect hit-ratio result.

Debugging is a major part of developing software and arguably the most
time consuming, and debugging distributed systems is especially hard.
Any tool that aids in debugging is highly valuable to any developer.
\demo{} can aid in both discovering and resolving bugs, as it provides
the developer with instant visual feedback of the protocol behaviour.

\subsection{Using Test-Driven Development}

Software Development Methodology is an active area of research
which is in part driven by the business needs of the private
sector\cite{janzen2005test}. One popular practice is so-called Test-Driven
Development (TDD). The promoters of TDD claims it increases
productivity and reduces the number of bugs and defects in the
code significantly~\cite{beck2003test}. Research
efforts performed at IBM~\cite{maximilien2003assessing} seems to
lend credibility to these claims. However, the use of TDD is not
prevalent in academia, and in~\cite{janzen2005test} they
recommend further research into the field in order to better
determine its effects.

Using TDD means writing tests before writing any code. There are
different types of test. \emph{unit tests} targets small,
independent pieces of code, typically methods within a single
module or component, while \emph{integration tests} aim to test
code across such modules and components in order to determine
how well they integrate with each other. In our work, we only
took advantage of Unit Tests where we found it to be suitable.
We could also have benefited from a suite of integration tests,
as our implementation is heavily dependent on interoperating
components, as well as file and network IO\@. However, writing
these sort of tests would simply be too time consuming compared
to writing smaller unit tests.

The TDD approach to software development is best described through the
Red-Green-Refactor mantra, which is a central part of the
TDD-philosophy. It can be described through the following steps:

\begin{description}
    \item[Step 1:] Write a test that fails. (Red)
    \item[Step 2:] Make the test pass. (Green)
    \item[Step 3:] Refactor the code while making sure the test
        still passes. (Refactor)
\end{description}

In our experience this routine has been helpful when working
with our implementation code, as it enables us as developer to
refactor with confidence achieving more maintainable code and a
more thoughtful software design. Since we share our
implementation code with the research community by hosting it in
a open repository, any tool or method that helps us improve the
design and maintainability of our project is of great value to
us. Using TDD forced us to think more deeply about what
functionality to implement and how to structure and split the
problem domain into smaller function points. We believe that in
the end, following TDD where its suitable is beneficial to both
programmer productivity as well as programmer happiness. Also,
we are confident that this practice decreased the amount of
technical debt in our project, a problem we find to be commonplace in academia.

\subsection{Sharing Code with the Community}

We believe sharing our code is to the benefit of both \demo{} and the
community. During our presentation at DEBS 2014, the interest in our
tool was high, and we received a fair amount of requests for our
implementation code. Sharing our code by hosting it publicly will
hopefully allow the tool to grow from a prototype into mature product by
allowing anyone to contribute with improvements and bug fixes. It is our
hope that \demo{} will be a lasting contribution to the research
community, and hosting the code publicly is a key part in ensuring the
future of the tool.

\section{Chapter Summary}

In this chapter we presented \demo{}~\cite{korsveien2014vizpub}, a tool we propose for visualizing
the performance of overlay-based pub/sub systems. To the best of our
knowledge, this is the first tool of its kind. It is designed to be a
generic tool, intended to be used with any pub/sub system. We describe
\demo{} and its system architecture, as well as demonstrate the usage of
the tool through examples of visualizations. \demo{} is able to produce
two different types of visualizations: (1) visualization of overlay
structure, and (2)  visualization of publication message dissemination.
We also describe our own experiences working with the tool, and how it
aided us in debugging as well as in better understanding the
characteristics of the different pub/sub protocols in question. We
believe our tool is a useful contribution which has value both for
researchers, developers as well as students of distributed systems. We
share our implementation code by hosting it in a public
repository~\footnote{\url{http://github.com/vizpub/vizpub}} in order to
encourage its further development. We presented a poster and held a
demonstration of \demo{} at DEBS 2014 where we were awarded with the
price for best poster/demo. We are encouraged by the feedback received
from the researchers who visited our demo at DEBS, and we hope our tool
will serve as a lasting contribution to the research community.

